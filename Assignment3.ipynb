{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgVtkIXKEVxRF22+Sdupi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trilokimodi/lt2222-v23-a3/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z7b9U4R3vPAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b67af2-e437-46bd-f95a-36eb5dcf7ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import io\n",
        "from torch import nn\n",
        "from torch.utils.data.dataset import random_split"
      ],
      "metadata": {
        "id": "2TV8Oq3avweq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As instructed the data is in data folder and I assume that CWD is one directory before data dir.\n",
        "dataset = os.path.join(os.getcwd(), 'data')  # To run in MLTGPU\n",
        "dataset = \"/content/drive/My Drive/MLSNLP/data/enron_sample\"  # To run in Colab\n",
        "#  dataset = \"/scratch/lt2222-v23/enron_sample\" # To run in mltgpu"
      ],
      "metadata": {
        "id": "WUEsD9XNvVsj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(dataset)"
      ],
      "metadata": {
        "id": "twfYErePv4HP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3798f3fe-ca0c-4e41-ca49-5dd173e2260a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corman-s',\n",
              " 'lenhart-m',\n",
              " 'donohoe-t',\n",
              " 'may-l',\n",
              " 'bailey-s',\n",
              " 'keiser-k',\n",
              " 'panus-s',\n",
              " 'dean-c',\n",
              " 'mccarty-d',\n",
              " 'lay-k',\n",
              " 'salisbury-h',\n",
              " 'schwieger-j',\n",
              " 'saibi-e',\n",
              " 'quigley-d']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "    "
      ],
      "metadata": {
        "id": "rJq6FaPUv6sP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = [os.path.join(os.path.join(dataset, iClass), iText) for iClass in os.listdir(dataset) for iText in os.listdir(os.path.join(dataset, iClass))]\n",
        "dataset_paths = [iPath for iPath in dataset_paths if '_edit' not in iPath]\n",
        "labelEncoder = LabelEncoder()\n",
        "labelEncoder.fit(os.listdir(dataset))"
      ],
      "metadata": {
        "id": "ULSoexZLpFL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "04700dfb-f41e-4bea-8306-ad9671e911ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "wOSbiGA2t2Dv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "for iPath in dataset_paths:\n",
        "    newFile = list()\n",
        "    with io.open(iPath, encoding = 'utf-8') as fh:\n",
        "        for line in fh:\n",
        "            if line.startswith(('Message-ID', 'Mime-Version:', 'Content-Type:', 'Content-Transfer-Encoding:')):\n",
        "                pass\n",
        "            elif line.startswith(('X-From:', 'X-To:', 'X-cc:', 'X-bcc:', 'X-Folder:', 'X-Origin:', 'X-FileName:')):\n",
        "                pass\n",
        "            elif re.search('From:', line) is not None:\n",
        "                pass\n",
        "            elif re.search('To:', line) is not None:\n",
        "                pass\n",
        "            elif re.search('Date:', line) is not None:\n",
        "                pass\n",
        "            elif re.search('Sent:', line) is not None:\n",
        "                pass\n",
        "            elif re.search(' -----Original Message-----', line) is not None:\n",
        "                pass\n",
        "            else:\n",
        "                newFile.append(line)\n",
        "    fh.close()\n",
        "\n",
        "    with open(iPath + '_edit', 'w') as fh:\n",
        "        for line in newFile:\n",
        "            fh.write(line)\n",
        "    fh.close()"
      ],
      "metadata": {
        "id": "L1OtG0_kM0Cx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with io.open(dataset_paths[110], encoding = 'utf-8') as fh:\n",
        "    print(fh.readlines())\n",
        "fh.close()"
      ],
      "metadata": {
        "id": "sig2A2HLUmHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f0ec0f-b1c9-47d4-f079-c04bd2196a4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Subject: RE: Web site\\n', '\\n', 'Hi.  Thanks for the info.\\n', '\\n', 'Subject:\\tWeb site\\n', '\\n', \"Hi Shelley - Welcome home!  I hear you are feeling somewhat better.  Can't wait to see you again.  Rob said to forward this to you.\\n\", '\\n', '\\n', '\\n', 'http://energycommerce.house.gov/\\n', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with io.open(dataset_paths[110] + '_edit', encoding = 'utf-8') as fh:\n",
        "    print(fh.readlines())\n",
        "fh.close()"
      ],
      "metadata": {
        "id": "duMGFhXOUuSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17db0c35-5e0f-47b3-9022-96382344c892"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Subject: RE: Web site\\n', '\\n', 'Hi.  Thanks for the info.\\n', '\\n', 'Subject:\\tWeb site\\n', '\\n', \"Hi Shelley - Welcome home!  I hear you are feeling somewhat better.  Can't wait to see you again.  Rob said to forward this to you.\\n\", '\\n', '\\n', '\\n', 'http://energycommerce.house.gov/\\n', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = [iPath + '_edit' for iPath in dataset_paths]"
      ],
      "metadata": {
        "id": "lGWyeNB5Vb8g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(paths):\n",
        "    for iPath in paths:\n",
        "        with io.open(iPath, encoding = 'utf-8') as fh:\n",
        "            for line in fh:\n",
        "                yield tokenizer(line)\n",
        "        fh.close()"
      ],
      "metadata": {
        "id": "g0L1LnyatwvY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabObject = build_vocab_from_iterator(yield_tokens(dataset_paths), specials=[\"<unk>\"])\n",
        "vocabObject.set_default_index(vocabObject[\"<unk>\"])"
      ],
      "metadata": {
        "id": "51CfoztjuFtZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabObject)"
      ],
      "metadata": {
        "id": "jptWZ-upV6T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878ce584-eb9a-4a24-9100-f917e30b25b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20194"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataset_paths=dataset_paths, labelEncoder=labelEncoder, tokenizer=tokenizer, vocab=vocabObject):\n",
        "        self.datasetPaths = dataset_paths\n",
        "        self.labelEncoder = labelEncoder\n",
        "        self.tokenizer=tokenizer\n",
        "        self.vocab=vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datasetPaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        docFilePath = self.datasetPaths[idx]\n",
        "        text_pipeline = lambda x: self.vocab(self.tokenizer(x))\n",
        "        with io.open(docFilePath, encoding = 'utf-8') as fh:\n",
        "            content = fh.readlines()\n",
        "        content = ''.join(content)\n",
        "        textTensor = torch.tensor(text_pipeline(content), dtype=torch.int64)\n",
        "        label = docFilePath.split('/')[-2]\n",
        "        label = self.labelEncoder.transform([label])\n",
        "        return textTensor, label[0]"
      ],
      "metadata": {
        "id": "PEdBvXj_4A2S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_data = TextDataset()"
      ],
      "metadata": {
        "id": "SCfHT-hAkbj9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size=len(vocabObject), embed_dim=50, num_class=len(labelEncoder.classes_)):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "GtgJKZrytHNU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_text, _label) in batch:\n",
        "         text_list.append(_text)\n",
        "         label_list.append(_label)\n",
        "         offsets.append(_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    text_list = torch.cat(text_list)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    return text_list.to(device), label_list.to(device), offsets.to(device)"
      ],
      "metadata": {
        "id": "GbpODnZbHPzG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TextClassificationModel().to(device)"
      ],
      "metadata": {
        "id": "3w-1QxFvwAFN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (text, label, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(epoch, idx, len(dataloader), total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (text, label, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "J5JhCg9p0vMD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data = dataset_paths, columns=['X'])\n",
        "df['y'] = df['X'].apply(lambda x: x.split('/')[-2])"
      ],
      "metadata": {
        "id": "8505uAKy1WKd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prop = int(len(complete_data) * 0.80)\n",
        "train_data, test_data = random_split(complete_data, [train_prop, len(complete_data) - train_prop])"
      ],
      "metadata": {
        "id": "xyHDviZJ2pvg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_dataset = to_map_style_dataset(train_data)\n",
        "test_dataset = to_map_style_dataset(test_data)\n",
        "num_train = int(len(train_data) * 0.95)\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_data) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "id": "JWz4BOJ_1Isz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccb9514-a190-4eb7-da80-5cdca5f616a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  0.62s | valid accuracy    0.799 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  0.48s | valid accuracy    0.848 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  0.45s | valid accuracy    0.914 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  0.47s | valid accuracy    0.889 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  0.49s | valid accuracy    0.922 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  0.52s | valid accuracy    0.922 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  1.05s | valid accuracy    0.926 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  1.41s | valid accuracy    0.926 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  1.89s | valid accuracy    0.930 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  1.43s | valid accuracy    0.934 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "metadata": {
        "id": "ten5eqNBK0sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848bd85e-4dae-4e78-80e7-f95226c9a350"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.924\n"
          ]
        }
      ]
    }
  ]
}